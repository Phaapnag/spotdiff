import os
import time
from typing import List, Tuple

import cv2
import numpy as np
from PIL import Image
import moviepy.editor as mpy
import gradio as gr

# ====== åŸæœ‰åƒæ•¸ ======
OUTPUTDIR = "output"
FPS = 24
QUIZSECONDS = 10
ANSWERSECONDS = 2
TITLE = "æ‰¾ä¸åŒ Shorts ç”Ÿæˆå™¨"


# ====== å…±ç”¨å‡½æ•¸ ======
def load_and_align_images(base_img: Image.Image, variant_img: Image.Image):
    """å°‡å…©å¼µ PIL Image å°é½Šåˆ°ç›¸åŒå°ºå¯¸ã€‚"""
    img1 = base_img.convert("RGB")
    img2 = variant_img.convert("RGB")
    w, h = img1.size
    if img2.size != (w, h):
        img2 = img2.resize((w, h), Image.LANCZOS)
    return img1, img2


def draw_circles_on_image(
    img: Image.Image,
    points: List[Tuple[int, int]],
    radius: int,
    thickness: int,
    color=(255, 0, 0),
) -> Image.Image:
    """åœ¨ PIL åœ–ç‰‡ä¸Šç•«ç´…åœˆï¼Œå›å‚³æ–°çš„ PIL åœ–ç‰‡ã€‚"""
    if img is None:
        return None
    bgr = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
    for x, y in points:
        cv2.circle(bgr, (int(x), int(y)), int(radius), (0, 0, 255), int(thickness))
    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)
    return Image.fromarray(rgb)


def draw_text_opencv(imgbgr: np.ndarray, text: str):
    caption_font = cv2.FONT_HERSHEY_SIMPLEX
    scale = 1.2
    thickness = 2
    h, w = imgbgr.shape[:2]
    barheight = 60
    cv2.rectangle(imgbgr, (0, 0), (w, barheight), (0, 0, 0), -1)

    (textw, texth), _ = cv2.getTextSize(text, caption_font, scale, thickness)
    x = (w - textw) // 2
    y = (barheight + texth) // 2
    cv2.putText(imgbgr, text, (x, y), caption_font, scale, (255, 255, 255), thickness, cv2.LINE_AA)
    return imgbgr


def make_video_with_opencv_frames(
    img1: Image.Image, img2: Image.Image, img2_marked: Image.Image, outpath: str
):
    totalquizframes = QUIZSECONDS * FPS
    totalanswerframes = ANSWERSECONDS * FPS

    img1bgr = cv2.cvtColor(np.array(img1), cv2.COLOR_RGB2BGR)
    img2bgr = cv2.cvtColor(np.array(img2), cv2.COLOR_RGB2BGR)
    img2markedbgr = cv2.cvtColor(np.array(img2_marked), cv2.COLOR_RGB2BGR)

    h, w = img1bgr.shape[:2]
    
    # â˜… æ”¹ï¼šè¼¸å‡ºå½±ç‰‡æœ€å¤§å¯¬åº¦ 720ï¼ˆYouTube Shorts å¤ ç”¨ï¼‰ï¼Œæ¸›å°‘è¨˜æ†¶é«”
    MAX_VIDEO_WIDTH = 720
    if w > MAX_VIDEO_WIDTH:
        scale = MAX_VIDEO_WIDTH / w
        new_w = MAX_VIDEO_WIDTH
        new_h = int(h * scale)
        img1bgr = cv2.resize(img1bgr, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
        img2bgr = cv2.resize(img2bgr, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
        img2markedbgr = cv2.resize(img2markedbgr, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
        w, h = new_w, new_h

    fullheight = h * 2
    frames = []

    # Quiz éƒ¨åˆ†
    for i in range(totalquizframes):
        frame = np.zeros((fullheight, w, 3), dtype=np.uint8)
        frame[0:h, :, :] = img1bgr
        frame[h:fullheight, :, :] = img2bgr

        remaining = QUIZSECONDS - i / FPS
        text = f"æ‰¾å‡º 5 å€‹ä¸åŒï¼å‰©é¤˜ {remaining:.0f} ç§’"
        frame = draw_text_opencv(frame, text)
        frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))

    # Answer éƒ¨åˆ†
    for _ in range(totalanswerframes):
        frame = np.zeros((fullheight, w, 3), dtype=np.uint8)
        frame[0:h, :, :] = img1bgr
        frame[h:fullheight, :, :] = img2markedbgr
        frame = draw_text_opencv(frame, "ç­”æ¡ˆåœ¨ä¸‹é¢ï¼")
        frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))

    clip = mpy.ImageSequenceClip(frames, fps=FPS)
    clip.write_videofile(outpath, codec="libx264", audio=False, preset="ultrafast")  # â˜… åŠ  preset åŠ é€Ÿ



# ====== Gradio ç›¸é—œå‡½æ•¸ ======
MAX_DISPLAY = 1024  # UI é¡¯ç¤ºæ™‚çš„æœ€å¤§é‚Šé•·ï¼ˆåƒç´ ï¼‰

def resize_for_display(img: Image.Image) -> Image.Image:
    w, h = img.size
    longest = max(w, h)
    if longest <= MAX_DISPLAY:
        return img  # å·²ç¶“ä¸å¤§ï¼Œç›´æ¥ç”¨
    scale = MAX_DISPLAY / float(longest)
    new_size = (int(w * scale), int(h * scale))
    return img.resize(new_size, Image.LANCZOS)


# å¤šåŠ ä¸€å€‹ state å­˜é«˜æ¸…åœ–
base_full_state = gr.State(None)
variant_full_state = gr.State(None)

def step1_align(base_file, variant_file):
    """Step1: ä¸Šå‚³å…©å¼µåœ–ä¸¦å°é½Šï¼Œå›å‚³çµ¦ UI ç”¨çš„ã€ç¸®ç´°ç‰ˆã€‘ base / variantï¼Œä¸¦ä¿å­˜åŸå§‹åœ–åˆ° stateã€‚"""
    os.makedirs(OUTPUTDIR, exist_ok=True)
    if base_file is None or variant_file is None:
        return None, None, None, None, None

    base_img = Image.fromarray(base_file) if isinstance(base_file, np.ndarray) else base_file
    variant_img = (
        Image.fromarray(variant_file) if isinstance(variant_file, np.ndarray) else variant_file
    )

    # å…ˆå°é½ŠåŸå§‹å°ºå¯¸ï¼ˆé«˜æ¸…ï¼‰
    img1, img2 = load_and_align_images(base_img, variant_img)

    # å­˜ä¸€ä»½ã€ŒåŸåœ–å°é½Šã€çµ¦ä¹‹å¾Œåšå½±ç‰‡ç”¨ï¼ˆå¯é¸ï¼Œå‚™ä»½ï¼‰
    base_aligned = os.path.join(OUTPUTDIR, "base_aligned.jpg")
    variant_aligned = os.path.join(OUTPUTDIR, "variant_aligned.jpg")
    img1.save(base_aligned)
    img2.save(variant_aligned)

    # è½‰æˆ numpyï¼Œæ”¾åœ¨ state è£¡ï¼ˆé«˜æ¸…ç‰ˆæœ¬ï¼‰
    base_np = np.array(img1)
    variant_np = np.array(img2)

    # å†åšä¸€ä»½ã€Œç¸®ç´°ç‰ˆã€çµ¦ UI é¡¯ç¤ºï¼Œæ¸›å°‘æ¯æ¬¡ç•«åœˆå‚³è¼¸é‡
    img1_disp = resize_for_display(img1)
    img2_disp = resize_for_display(img2)

    # å›å‚³ï¼šé¡¯ç¤ºç”¨ baseã€é¡¯ç¤ºç”¨ variantã€åŸå§‹é¡¯ç¤ºç”¨ variantã€é«˜æ¸… baseã€é«˜æ¸… variant
    return img1_disp, img2_disp, img2_disp, base_np, variant_np
    





def on_click_variant(variant_original, evt: gr.SelectData, radius, thickness, points):
    """åœ¨è®Šé«”åœ–ä¸Šé»æ“Šæ™‚ï¼Œæ–°å¢ä¸€å€‹ç´…åœˆä¸¦å›å‚³æ–°çš„åœ–èˆ‡ pointsã€‚"""
    if variant_original is None:
        return None, points

    x, y = evt.index
    points = list(points or [])

    # é™åˆ¶æœ€å¤š 5 å€‹é»
    if len(points) >= 5:
        marked = draw_circles_on_image(variant_original, points, radius, thickness)
        return np.array(marked), points

    points.append((x, y))
    marked = draw_circles_on_image(variant_original, points, radius, thickness)
    return np.array(marked), points



def reset_points(variant_original):
    """é‡è¨­ç´…åœˆï¼šå›åˆ°åŸå§‹è®Šé«”åœ–ï¼Œæ¸…ç©º pointsã€‚"""
    if variant_original is None:
        return None, []
    return np.array(variant_original), []


def undo_last_point(variant_original, points, radius, thickness):
    """åˆªé™¤æœ€å¾Œä¸€å€‹ç´…åœˆä¸¦é‡ç•«ã€‚"""
    points = list(points or [])
    if not points or variant_original is None:
        return (np.array(variant_original) if variant_original is not None else None), points

    points.pop()
    marked = draw_circles_on_image(variant_original, points, radius, thickness)
    return np.array(marked), points

def preview_final_frames(points, radius, thickness):
    """ç”Ÿæˆæœ€çµ‚å…©å¼µåˆæˆåœ–ï¼šä¸Š = base+variantï¼ˆç„¡åœˆï¼‰ï¼Œä¸‹ = base+variantï¼ˆæœ‰åœˆï¼‰ã€‚"""
    if not points:
        raise gr.Error("è«‹å…ˆåœ¨æ­¥é©Ÿ 1 æ¨™è¨˜ç´…åœˆã€‚")

    base_path = os.path.join(OUTPUTDIR, "base_aligned.jpg")
    variant_path = os.path.join(OUTPUTDIR, "variant_aligned.jpg")
    if not (os.path.exists(base_path) and os.path.exists(variant_path)):
        raise gr.Error("è«‹å…ˆå®Œæˆæ­¥é©Ÿ 1 ä¸Šå‚³ä¸¦å°é½Šåœ–ç‰‡ã€‚")

    img1 = Image.open(base_path).convert("RGB")
    img2 = Image.open(variant_path).convert("RGB")
    img2_marked = draw_circles_on_image(img2, points, radius, thickness)

    w, h = img1.size
    fullheight = h * 2

    # åˆæˆåœ– 1ï¼šbase ä¸Š + variant ä¸‹ï¼ˆç„¡åœˆï¼‰
    canvas1 = np.zeros((fullheight, w, 3), dtype=np.uint8)
    canvas1[0:h, :, :] = cv2.cvtColor(np.array(img1), cv2.COLOR_RGB2BGR)
    canvas1[h:fullheight, :, :] = cv2.cvtColor(np.array(img2), cv2.COLOR_RGB2BGR)
    preview1 = cv2.cvtColor(canvas1, cv2.COLOR_BGR2RGB)

    # åˆæˆåœ– 2ï¼šbase ä¸Š + variant ä¸‹ï¼ˆæœ‰åœˆï¼‰
    canvas2 = np.zeros((fullheight, w, 3), dtype=np.uint8)
    canvas2[0:h, :, :] = cv2.cvtColor(np.array(img1), cv2.COLOR_RGB2BGR)
    canvas2[h:fullheight, :, :] = cv2.cvtColor(np.array(img2_marked), cv2.COLOR_RGB2BGR)
    preview2 = cv2.cvtColor(canvas2, cv2.COLOR_BGR2RGB)

    return Image.fromarray(preview1), Image.fromarray(preview2)


def step2_make_video(base_full, variant_full, points, radius, thickness):
    """Step2: ç”¨ state è£¡çš„é«˜æ¸… base / variant + points ç”Ÿæˆå½±ç‰‡ã€‚"""
    if base_full is None or variant_full is None:
        raise gr.Error("è«‹å…ˆåœ¨æ­¥é©Ÿ 1 ä¸Šå‚³ä¸¦å°é½Šåœ–ç‰‡ï¼ˆæŒ‰ä¸€æ¬¡ã€é–‹å§‹ï¼ˆä¸Šå‚³ & å°é½Šï¼‰ã€ï¼‰ã€‚")

    if not points:
        raise gr.Error("è«‹å…ˆåœ¨è®Šé«”åœ–ä¸Šé»æ“Šï¼Œæ¨™è¨˜è‡³å°‘ 1 å€‹ç´…åœˆï¼ˆæœ€å¤š 5 å€‹ï¼‰ã€‚")

    import numpy as np  # ä¸Šé¢å·²ç¶“æœ‰

    # å¦‚æœæ˜¯ listï¼Œå°±å–ç¬¬ä¸€å€‹å…ƒç´ 
    if isinstance(base_full, list):
        base_full = base_full[0]
    if isinstance(variant_full, list):
        variant_full = variant_full[0]

    img1 = Image.fromarray(np.array(base_full))
    img2 = Image.fromarray(np.array(variant_full))


    # ç•«ä¸Šç´…åœˆï¼Œå¾—åˆ°æ¨™è¨˜å¾Œçš„è®Šé«”åœ–
    img2_marked = draw_circles_on_image(img2, points, radius, thickness)
    marked_path = os.path.join(OUTPUTDIR, "variant_marked.jpg")
    img2_marked.save(marked_path)

    # ç”Ÿæˆå½±ç‰‡
    os.makedirs(OUTPUTDIR, exist_ok=True)
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    video_filename = f"spotdiff_{timestamp}.mp4"
    video_path = os.path.join(OUTPUTDIR, video_filename)

    make_video_with_opencv_frames(img1, img2, img2_marked, video_path)
    return video_path



# ====== å»ºç«‹ Gradio ä»‹é¢ ======
with gr.Blocks(title="æ‰¾ä¸åŒ Shorts ç”Ÿæˆå™¨") as demo:
    gr.Markdown(
        "## ğŸ” æ‰¾ä¸åŒ Shorts ç”Ÿæˆå™¨\n"
        "1ï¸âƒ£ ä¸Šå‚³å…©å¼µåœ– â†’ 2ï¸âƒ£ åœ¨ä¸‹æ–¹è®Šé«”åœ–é» 5 å€‹ç´…åœˆï¼ˆå¯èª¿åœˆåœˆå¤§å° & ç²—å¹¼, ä¸­é€”ä¸è¦å†æŒ‰ã€Œé–‹å§‹ã€ï¼‰â†’ "
        "3ï¸âƒ£ ç”Ÿæˆ 12 ç§’ YouTube Shorts MP4ï¼"
    )

    # State ç”¨ä¾†å­˜ points
    points_state = gr.State([])
    variant_original_state = gr.State(None)  # â˜… æ–°å¢ï¼šä¿å­˜ã€Œæœªç•«åœˆã€çš„è®Šé«”åœ–
    base_full_state = gr.State(None)      # å­˜é«˜æ¸…çš„ base
    variant_full_state = gr.State(None)   # å­˜é«˜æ¸…çš„ variant

    
    with gr.Tab("æ­¥é©Ÿ 1ï¼šä¸Šå‚³ & å°é½Š"):
        with gr.Row():
            base_input = gr.Image(label="ğŸ“¸ ä¸Šå‚³åŸºæº–åœ– (base)", type="pil")
            variant_input = gr.Image(label="ğŸ“¸ ä¸Šå‚³è®Šé«”åœ– (variant)", type="pil")
        align_button = gr.Button("âœ… å°é½Šä¸¦é¡¯ç¤º")

        with gr.Row():
            base_show = gr.Image(
                label="åŸºæº–åœ– (å·²å°é½Š)",
                height=600,
            )
            variant_show = gr.Image(
                label="è®Šé«”åœ– (é»æ“Šç•«ç´…åœˆ)", 
                interactive=True, 
                height=600,
            )

        radius_slider = gr.Slider(
            minimum=10,
            maximum=300,
            value=40,
            step=2,
            label="ğŸ”´ ç´…åœˆåŠå¾‘ (è¶Šå¤§åœˆè¶Šå¤§)",
        )
        thickness_slider = gr.Slider(
            minimum=2,
            maximum=20,
            value=6,
            step=1,
            label="ğŸ–Š ç·šæ¢ç²—å¹¼",
        )
        reset_button = gr.Button("â™»ï¸ é‡è¨­æ‰€æœ‰ç´…åœˆ")
        undo_button = gr.Button("â†©ï¸ Undo ä¸Šä¸€å€‹ç´…åœˆ")   # â˜… æ–°å¢


        # Step1 å°é½Š
        align_button.click(
        fn=step1_align,
        inputs=[base_input, variant_input],
        outputs=[base_show, variant_show, variant_original_state, base_full_state, variant_full_state],
        )


        # é»æ“Šè®Šé«”åœ–æ™‚ç•«åœˆ
        variant_show.select(
            fn=on_click_variant,
            inputs=[variant_original_state, radius_slider, thickness_slider, points_state],
            outputs=[variant_show, points_state],
        )


        # é‡è¨­ç´…åœˆ
        reset_button.click(
            fn=reset_points,
            inputs=[variant_original_state],
            outputs=[variant_show, points_state],
        )


        # Undo æœ€å¾Œä¸€å€‹ç´…åœˆ
        undo_button.click(
            fn=undo_last_point,
            inputs=[variant_original_state, points_state, radius_slider, thickness_slider],
            outputs=[variant_show, points_state],
        )



    with gr.Tab("æ­¥é©Ÿ 2ï¼šç”Ÿæˆå½±ç‰‡"):
        gr.Markdown("ç¢ºèªç´…åœˆå¾Œï¼Œå…ˆé è¦½åˆæˆæ•ˆæœï¼Œå†ç”Ÿæˆ 12 ç§’å½±ç‰‡ã€‚")
        
        preview_button = gr.Button("ğŸ” é è¦½åˆæˆåœ–ï¼ˆå½±ç‰‡å‰ 10 ç§’ vs å¾Œ 2 ç§’ï¼‰")
        with gr.Row():
            preview_quiz = gr.Image(label="ğŸ“º Quiz ç•«é¢ï¼šbase + variantï¼ˆç„¡åœˆï¼‰")
            preview_answer = gr.Image(label="ğŸ“º Answer ç•«é¢ï¼šbase + variantï¼ˆæœ‰åœˆï¼‰")
        
        make_video_button = gr.Button("ğŸ¥ ç¢ºèªç„¡èª¤ï¼Œç”Ÿæˆ 12 ç§’ MP4")
        video_output = gr.Video(label="è¼¸å‡ºå½±ç‰‡", interactive=False)

        # é è¦½
        preview_button.click(
            fn=preview_final_frames,
            inputs=[points_state, radius_slider, thickness_slider],
            outputs=[preview_quiz, preview_answer],
        )

        # ç”Ÿæˆå½±ç‰‡
        make_video_button.click(
            fn=step2_make_video,
            inputs=[points_state, radius_slider, thickness_slider],
            outputs=video_output,
        )



if __name__ == "__main__":
    os.makedirs(OUTPUTDIR, exist_ok=True)
    demo.launch(server_name="0.0.0.0", server_port=int(os.environ.get("PORT", 7860)))
