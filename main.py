import os
import time
from typing import List, Tuple

import cv2
import numpy as np
from PIL import Image
import moviepy.editor as mpy
import gradio as gr

# ====== åŸæœ‰åƒæ•¸ ======
OUTPUTDIR = "output"
FPS = 24
QUIZSECONDS = 10
ANSWERSECONDS = 2
TITLE = "æ‰¾ä¸åŒ Shorts ç”Ÿæˆå™¨"


# ====== å…±ç”¨å‡½æ•¸ ======
def load_and_align_images(base_img: Image.Image, variant_img: Image.Image):
    """å°‡å…©å¼µ PIL Image å°é½Šåˆ°ç›¸åŒå°ºå¯¸ã€‚"""
    img1 = base_img.convert("RGB")
    img2 = variant_img.convert("RGB")
    w, h = img1.size
    if img2.size != (w, h):
        img2 = img2.resize((w, h), Image.LANCZOS)
    return img1, img2


def draw_circles_on_image(
    img: Image.Image,
    points: List[Tuple[int, int]],
    radius: int,
    thickness: int,
    color=(255, 0, 0),
) -> Image.Image:
    """åœ¨ PIL åœ–ç‰‡ä¸Šç•«ç´…åœˆï¼Œå›å‚³æ–°çš„ PIL åœ–ç‰‡ã€‚"""
    if img is None:
        return None
    bgr = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
    for x, y in points:
        cv2.circle(bgr, (int(x), int(y)), int(radius), (0, 0, 255), int(thickness))
    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)
    return Image.fromarray(rgb)


def draw_text_opencv(imgbgr: np.ndarray, text: str):
    caption_font = cv2.FONT_HERSHEY_SIMPLEX
    scale = 1.2
    thickness = 2
    h, w = imgbgr.shape[:2]
    barheight = 60
    cv2.rectangle(imgbgr, (0, 0), (w, barheight), (0, 0, 0), -1)

    (textw, texth), _ = cv2.getTextSize(text, caption_font, scale, thickness)
    x = (w - textw) // 2
    y = (barheight + texth) // 2
    cv2.putText(imgbgr, text, (x, y), caption_font, scale, (255, 255, 255), thickness, cv2.LINE_AA)
    return imgbgr


def make_video_with_opencv_frames(
    img1: Image.Image, img2: Image.Image, img2_marked: Image.Image, outpath: str
):
    totalquizframes = QUIZSECONDS * FPS
    totalanswerframes = ANSWERSECONDS * FPS

    img1bgr = cv2.cvtColor(np.array(img1), cv2.COLOR_RGB2BGR)
    img2bgr = cv2.cvtColor(np.array(img2), cv2.COLOR_RGB2BGR)
    img2markedbgr = cv2.cvtColor(np.array(img2_marked), cv2.COLOR_RGB2BGR)

    h, w = img1bgr.shape[:2]
    width = w
    fullheight = h * 2
    frames = []

    # Quiz éƒ¨åˆ†
    for i in range(totalquizframes):
        frame = np.zeros((fullheight, width, 3), dtype=np.uint8)
        frame[0:h, :, :] = img1bgr
        frame[h:fullheight, :, :] = img2bgr

        remaining = QUIZSECONDS - i / FPS
        text = f"æ‰¾å‡º 5 å€‹ä¸åŒï¼å‰©é¤˜ {remaining:.0f} ç§’"
        frame = draw_text_opencv(frame, text)

        framesmall = cv2.resize(frame, (width // 2, fullheight // 2), interpolation=cv2.INTER_LINEAR)
        frames.append(cv2.cvtColor(framesmall, cv2.COLOR_BGR2RGB))

    # Answer éƒ¨åˆ†
    for _ in range(totalanswerframes):
        frame = np.zeros((fullheight, width, 3), dtype=np.uint8)
        frame[0:h, :, :] = img1bgr
        frame[h:fullheight, :, :] = img2markedbgr

        frame = draw_text_opencv(frame, "ç­”æ¡ˆåœ¨ä¸‹é¢ï¼")

        framesmall = cv2.resize(frame, (width // 2, fullheight // 2), interpolation=cv2.INTER_LINEAR)
        frames.append(cv2.cvtColor(framesmall, cv2.COLOR_BGR2RGB))

    clip = mpy.ImageSequenceClip(frames, fps=FPS)
    clip.write_videofile(outpath, codec="libx264", audio=False)


# ====== Gradio ç›¸é—œå‡½æ•¸ ======
MAX_DISPLAY = 1024  # UI é¡¯ç¤ºæ™‚çš„æœ€å¤§é‚Šé•·ï¼ˆåƒç´ ï¼‰

def resize_for_display(img: Image.Image) -> Image.Image:
    w, h = img.size
    longest = max(w, h)
    if longest <= MAX_DISPLAY:
        return img  # å·²ç¶“ä¸å¤§ï¼Œç›´æ¥ç”¨
    scale = MAX_DISPLAY / float(longest)
    new_size = (int(w * scale), int(h * scale))
    return img.resize(new_size, Image.LANCZOS)


def step1_align(base_file, variant_file):
    """Step1: ä¸Šå‚³å…©å¼µåœ–ä¸¦å°é½Šï¼Œå›å‚³çµ¦ UI ç”¨çš„ã€ç¸®ç´°ç‰ˆã€‘ base / variantã€‚"""
    os.makedirs(OUTPUTDIR, exist_ok=True)
    if base_file is None or variant_file is None:
        return None, None

    base_img = Image.fromarray(base_file) if isinstance(base_file, np.ndarray) else base_file
    variant_img = (
        Image.fromarray(variant_file) if isinstance(variant_file, np.ndarray) else variant_file
    )

    # å…ˆå°é½ŠåŸå§‹å°ºå¯¸
    img1, img2 = load_and_align_images(base_img, variant_img)

    # å­˜ä¸€ä»½ã€ŒåŸåœ–å°é½Šã€çµ¦ä¹‹å¾Œåšå½±ç‰‡ç”¨ï¼ˆå¦‚æœä½ ç¾åœ¨å½±ç‰‡ä¹Ÿæ˜¯ç”¨ base_aligned / variant_alignedï¼‰
    base_aligned = os.path.join(OUTPUTDIR, "base_aligned.jpg")
    variant_aligned = os.path.join(OUTPUTDIR, "variant_aligned.jpg")
    img1.save(base_aligned)
    img2.save(variant_aligned)

    # å†åšä¸€ä»½ã€Œç¸®ç´°ç‰ˆã€çµ¦ UI é¡¯ç¤ºï¼Œæ¸›å°‘æ¯æ¬¡ç•«åœˆå‚³è¼¸é‡
    img1_disp = resize_for_display(img1)
    img2_disp = resize_for_display(img2)

    return img1_disp, img2_disp



def on_click_variant(img, evt: gr.SelectData, radius, thickness, points):
    """åœ¨è®Šé«”åœ–ä¸Šé»æ“Šæ™‚ï¼Œæ–°å¢ä¸€å€‹ç´…åœˆä¸¦å›å‚³æ–°çš„åœ–èˆ‡ pointsã€‚"""
    if img is None:
        return None, points

    # evt.index = (x, y)
    x, y = evt.index
    points = list(points or [])

    # é™åˆ¶æœ€å¤š 5 å€‹é»
    if len(points) >= 5:
        return draw_circles_on_image(Image.fromarray(img), points, radius, thickness), points

    points.append((x, y))
    marked = draw_circles_on_image(Image.fromarray(img), points, radius, thickness)
    return np.array(marked), points


def reset_points(img):
    """é‡è¨­ç´…åœˆã€‚"""
    return img, []

def undo_last_point(img, points, radius, thickness):
    """åˆªé™¤æœ€å¾Œä¸€å€‹ç´…åœˆä¸¦é‡ç•«ã€‚"""
    points = list(points or [])
    if not points:
        return img, points  # æ²’æœ‰é»å°±ä¸è®Š

    points.pop()  # åˆªæ‰æœ€å¾Œä¸€å€‹
    if img is None:
        return img, points

    # é‡æ–°åœ¨åŸåœ–ä¸Šç•«å‰©ä¸‹çš„é»
    pil_img = Image.fromarray(img) if isinstance(img, np.ndarray) else img
    marked = draw_circles_on_image(pil_img, points, radius, thickness)
    return np.array(marked), points


def step2_make_video(points, radius, thickness):
    """Step2: ç”¨ base_aligned + variant_aligned + points ç”Ÿæˆå½±ç‰‡ã€‚"""
    if not points:
        raise gr.Error("è«‹å…ˆåœ¨è®Šé«”åœ–ä¸Šé»æ“Šï¼Œæ¨™è¨˜è‡³å°‘ 1 å€‹ç´…åœˆï¼ˆæœ€å¤š 5 å€‹ï¼‰ã€‚")

    base_path = os.path.join(OUTPUTDIR, "base_aligned.jpg")
    variant_path = os.path.join(OUTPUTDIR, "variant_aligned.jpg")
    if not (os.path.exists(base_path) and os.path.exists(variant_path)):
        raise gr.Error("è«‹å…ˆå®Œæˆæ­¥é©Ÿ 1 ä¸Šå‚³ä¸¦å°é½Šåœ–ç‰‡ã€‚")

    img1 = Image.open(base_path).convert("RGB")
    img2 = Image.open(variant_path).convert("RGB")

    img2_marked = draw_circles_on_image(img2, points, radius, thickness)
    marked_path = os.path.join(OUTPUTDIR, "variant_marked.jpg")
    img2_marked.save(marked_path)

    timestamp = time.strftime("%Y%m%d_%H%M%S")
    video_filename = f"spotdiff_{timestamp}.mp4"
    video_path = os.path.join(OUTPUTDIR, video_filename)

    make_video_with_opencv_frames(img1, img2, img2_marked, video_path)
    return video_path


# ====== å»ºç«‹ Gradio ä»‹é¢ ======
with gr.Blocks(title="æ‰¾ä¸åŒ Shorts ç”Ÿæˆå™¨") as demo:
    gr.Markdown(
        "## ğŸ” æ‰¾ä¸åŒ Shorts ç”Ÿæˆå™¨\n"
        "1ï¸âƒ£ ä¸Šå‚³å…©å¼µåœ– â†’ 2ï¸âƒ£ åœ¨ä¸‹æ–¹è®Šé«”åœ–é» 5 å€‹ç´…åœˆï¼ˆå¯èª¿åœˆåœˆå¤§å° & ç²—å¹¼ï¼‰â†’ "
        "3ï¸âƒ£ ç”Ÿæˆ 12 ç§’ YouTube Shorts MP4ï¼"
    )

    # State ç”¨ä¾†å­˜ points
    points_state = gr.State([])

    with gr.Tab("æ­¥é©Ÿ 1ï¼šä¸Šå‚³ & å°é½Š"):
        with gr.Row():
            base_input = gr.Image(label="ğŸ“¸ ä¸Šå‚³åŸºæº–åœ– (base)", type="pil")
            variant_input = gr.Image(label="ğŸ“¸ ä¸Šå‚³è®Šé«”åœ– (variant)", type="pil")
        align_button = gr.Button("âœ… å°é½Šä¸¦é¡¯ç¤º")

        with gr.Row():
            base_show = gr.Image(
                label="åŸºæº–åœ– (å·²å°é½Š)",
                height=600,
            )
            variant_show = gr.Image(
                label="è®Šé«”åœ– (é»æ“Šç•«ç´…åœˆ)", 
                interactive=True, 
                height=600,
            )

        radius_slider = gr.Slider(
            minimum=10,
            maximum=300,
            value=40,
            step=2,
            label="ğŸ”´ ç´…åœˆåŠå¾‘ (è¶Šå¤§åœˆè¶Šå¤§)",
        )
        thickness_slider = gr.Slider(
            minimum=2,
            maximum=20,
            value=6,
            step=1,
            label="ğŸ–Š ç·šæ¢ç²—å¹¼",
        )
        reset_button = gr.Button("â™»ï¸ é‡è¨­æ‰€æœ‰ç´…åœˆ")
        undo_button = gr.Button("â†©ï¸ Undo ä¸Šä¸€å€‹ç´…åœˆ")   # â˜… æ–°å¢


        # Step1 å°é½Š
        align_button.click(
            fn=step1_align,
            inputs=[base_input, variant_input],
            outputs=[base_show, variant_show],
        )

        # é»æ“Šè®Šé«”åœ–æ™‚ç•«åœˆ
        variant_show.select(
            fn=on_click_variant,
            inputs=[variant_show, radius_slider, thickness_slider, points_state],
            outputs=[variant_show, points_state],
        )

        # é‡è¨­ç´…åœˆ
        reset_button.click(
            fn=reset_points,
            inputs=[variant_show],
            outputs=[variant_show, points_state],
        )

        # Undo æœ€å¾Œä¸€å€‹ç´…åœˆ
        undo_button.click(
            fn=undo_last_point,
            inputs=[variant_show, points_state, radius_slider, thickness_slider],
            outputs=[variant_show, points_state],
        )


    with gr.Tab("æ­¥é©Ÿ 2ï¼šç”Ÿæˆå½±ç‰‡"):
        gr.Markdown("ç¢ºèªç´…åœˆå¾Œï¼ŒæŒ‰ä¸‹æ–¹æŒ‰éˆ•ç”Ÿæˆ 12 ç§’å½±ç‰‡ã€‚")
        make_video_button = gr.Button("ğŸ¥ ç”Ÿæˆ 12 ç§’ MP4")
        video_output = gr.Video(label="è¼¸å‡ºå½±ç‰‡", interactive=False)

        make_video_button.click(
            fn=step2_make_video,
            inputs=[points_state, radius_slider, thickness_slider],
            outputs=video_output,
        )


if __name__ == "__main__":
    os.makedirs(OUTPUTDIR, exist_ok=True)
    demo.launch(server_name="0.0.0.0", server_port=int(os.environ.get("PORT", 7860)))
